{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/7d/b1dedde8af99bd82f20ed7e9697aac0597de3049b1f786aa2aac3b9bd4da/Keras-2.2.2-py2.py3-none-any.whl (299kB)\n",
      "\u001b[K    100% |████████████████████████████████| 307kB 993kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/9a/426e1b3878098250e01f1cbb1645934e5835d620ae5e0cea8b6d6b8e9e72/tensorflow-1.10.1-cp36-cp36m-macosx_10_11_x86_64.whl (56.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 56.1MB 288kB/s ta 0:00:011    44% |██████████████▏                 | 24.7MB 1.5MB/s eta 0:00:22    77% |████████████████████████▉       | 43.5MB 1.3MB/s eta 0:00:10\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /anaconda3/lib/python3.6/site-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /anaconda3/lib/python3.6/site-packages (from keras) (1.14.3)\n",
      "Requirement already satisfied: pyyaml in /anaconda3/lib/python3.6/site-packages (from keras) (3.12)\n",
      "Collecting keras-applications==1.0.4 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/90/8f327deaa37a71caddb59b7b4aaa9d4b3e90c0e76f8c2d1572005278ddc5/Keras_Applications-1.0.4-py2.py3-none-any.whl (43kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 125kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing==1.0.2 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/71/26/1e778ebd737032749824d5cba7dbd3b0cf9234b87ab5ec79f5f0403ca7e9/Keras_Preprocessing-1.0.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: h5py in /anaconda3/lib/python3.6/site-packages (from keras) (2.7.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /anaconda3/lib/python3.6/site-packages (from keras) (1.1.0)\n",
      "Collecting absl-py>=0.1.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/db/cce5331638138c178dd1d5fb69f3f55eb3787a12efd9177177ae203e847f/absl-py-0.5.0.tar.gz (90kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 1.7MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\n",
      "Collecting protobuf>=3.6.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/27/133f225035b9539f2dcfebcdf9a69ff0152f56e0120160ec5c972ea7deb9/protobuf-3.6.1-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 1.4MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: setuptools<=39.1.0 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (39.1.0)\n",
      "Collecting tensorboard<1.11.0,>=1.10.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/17/ecd918a004f297955c30b4fffbea100b1606c225dbf0443264012773c3ff/tensorboard-1.10.0-py3-none-any.whl (3.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.3MB 730kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Requirement already satisfied: wheel>=0.26 in /anaconda3/lib/python3.6/site-packages (from tensorflow) (0.31.1)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/1a/84396834b04cd43be3c10f5faeadf62d01689b704b3c99d09e1e08a41d9b/grpcio-1.15.0-cp36-cp36m-macosx_10_7_intel.whl (2.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.0MB 1.2MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/78/ff794fcae2ce8aa6323e789d1f8b3b7765f601e7702726f430e814822b96/gast-0.2.0.tar.gz\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.11.0,>=1.10.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/fd/e22357c299e93c0bc11ec8ba54e79f98dd568e09adfe9b39d6852c744938/Markdown-3.0-py2.py3-none-any.whl (89kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 1.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.10 in /anaconda3/lib/python3.6/site-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow) (0.14.1)\n",
      "Building wheels for collected packages: absl-py, termcolor, gast\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/jester/Library/Caches/pip/wheels/3c/33/ae/db8cd618e62f87594c13a5483f96e618044f9b01596efd013f\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/jester/Library/Caches/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for gast ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/jester/Library/Caches/pip/wheels/9a/1f/0e/3cde98113222b853e98fc0a8e9924480a3e25f1b4008cedb4f\n",
      "Successfully built absl-py termcolor gast\n",
      "\u001b[31mdistributed 1.21.8 requires msgpack, which is not installed.\u001b[0m\n",
      "Installing collected packages: keras-applications, keras-preprocessing, keras, absl-py, astor, protobuf, markdown, tensorboard, termcolor, grpcio, gast, tensorflow\n",
      "Successfully installed absl-py-0.5.0 astor-0.7.1 gast-0.2.0 grpcio-1.15.0 keras-2.2.2 keras-applications-1.0.4 keras-preprocessing-1.0.2 markdown-3.0 protobuf-3.6.1 tensorboard-1.10.0 tensorflow-1.10.1 termcolor-1.1.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras import backend\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "img_paths = list(paths.list_images('datasets/animals/'))\n",
    "random.shuffle(img_paths)\n",
    "\n",
    "for img_path in img_paths :\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    label = img_path.split('/')[-2]\n",
    "    data.append(img)\n",
    "    labels.append(label)\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "data = data / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 98307     \n",
      "=================================================================\n",
      "Total params: 99,203\n",
      "Trainable params: 99,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# create kernel\n",
    "# activation ทำให้เป็น non linear\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        32, \n",
    "        (3, 3), \n",
    "        input_shape=(32, 32, 3), \n",
    "        activation='relu',\n",
    "        padding='same'\n",
    "    )\n",
    ")\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1920 samples, validate on 480 samples\n",
      "Epoch 1/10\n",
      "1920/1920 [==============================] - 2s 1ms/step - loss: 0.8942 - acc: 0.5646 - val_loss: 0.7188 - val_acc: 0.6667\n",
      "Epoch 2/10\n",
      "1920/1920 [==============================] - 2s 1ms/step - loss: 0.6296 - acc: 0.7208 - val_loss: 0.6702 - val_acc: 0.6896\n",
      "Epoch 3/10\n",
      "1920/1920 [==============================] - 2s 1ms/step - loss: 0.5201 - acc: 0.7802 - val_loss: 0.6942 - val_acc: 0.6813\n",
      "Epoch 4/10\n",
      "1920/1920 [==============================] - 2s 1ms/step - loss: 0.4248 - acc: 0.8495 - val_loss: 0.7544 - val_acc: 0.6104\n",
      "Epoch 5/10\n",
      "1920/1920 [==============================] - 2s 1ms/step - loss: 0.3712 - acc: 0.8656 - val_loss: 0.7223 - val_acc: 0.6875\n",
      "Epoch 6/10\n",
      "1920/1920 [==============================] - 2s 1ms/step - loss: 0.3054 - acc: 0.9068 - val_loss: 0.6992 - val_acc: 0.7167\n",
      "Epoch 7/10\n",
      "1920/1920 [==============================] - 2s 1ms/step - loss: 0.2526 - acc: 0.9333 - val_loss: 0.6897 - val_acc: 0.7188\n",
      "Epoch 8/10\n",
      "1920/1920 [==============================] - 2s 1ms/step - loss: 0.2151 - acc: 0.9432 - val_loss: 0.7539 - val_acc: 0.6854\n",
      "Epoch 9/10\n",
      "1920/1920 [==============================] - 3s 1ms/step - loss: 0.1992 - acc: 0.9437 - val_loss: 0.7797 - val_acc: 0.6792\n",
      "Epoch 10/10\n",
      "1920/1920 [==============================] - 2s 1ms/step - loss: 0.1640 - acc: 0.9667 - val_loss: 0.7495 - val_acc: 0.7042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb1e943ba8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cats', 'dogs', 'panda'], dtype='<U5')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.54      0.69      0.61       204\n",
      "       dogs       0.54      0.40      0.46       210\n",
      "      panda       0.83      0.81      0.82       186\n",
      "\n",
      "avg / total       0.63      0.63      0.62       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred.argmax(axis=1)\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "    y_test.argmax(axis=1), \n",
    "    y_pred.argmax(axis=1), \n",
    "    target_names=lb.classes_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32 คือ จำนวน kernal\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        32, \n",
    "        (3, 3), \n",
    "        input_shape=(32, 32, 3), \n",
    "        activation='relu',\n",
    "        padding='same'\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        128, \n",
    "        (3, 3), \n",
    "        activation='relu',\n",
    "        padding='same'\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        128, \n",
    "        (3, 3), \n",
    "        activation='relu',\n",
    "        padding='same'\n",
    "    )\n",
    ")\n",
    "\n",
    "# ใช้ค่ามากสุดตอนทาบ kernal\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1920 samples, validate on 480 samples\n",
      "Epoch 1/10\n",
      "1920/1920 [==============================] - 55s 29ms/step - loss: 0.8498 - acc: 0.5438 - val_loss: 0.7234 - val_acc: 0.6479\n",
      "Epoch 2/10\n",
      "1920/1920 [==============================] - 58s 30ms/step - loss: 0.6857 - acc: 0.6630 - val_loss: 0.7492 - val_acc: 0.6458\n",
      "Epoch 3/10\n",
      "1920/1920 [==============================] - 58s 30ms/step - loss: 0.6475 - acc: 0.6990 - val_loss: 0.8366 - val_acc: 0.5833\n",
      "Epoch 4/10\n",
      "1920/1920 [==============================] - 59s 31ms/step - loss: 0.5867 - acc: 0.7224 - val_loss: 0.7442 - val_acc: 0.6625\n",
      "Epoch 5/10\n",
      "1920/1920 [==============================] - 60s 31ms/step - loss: 0.5119 - acc: 0.7599 - val_loss: 0.6259 - val_acc: 0.7271\n",
      "Epoch 6/10\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 0.4558 - acc: 0.8000 - val_loss: 0.6364 - val_acc: 0.7167\n",
      "Epoch 7/10\n",
      "1920/1920 [==============================] - 62s 32ms/step - loss: 0.3950 - acc: 0.8250 - val_loss: 0.6975 - val_acc: 0.6958\n",
      "Epoch 8/10\n",
      "1920/1920 [==============================] - 60s 31ms/step - loss: 0.3528 - acc: 0.8422 - val_loss: 0.8066 - val_acc: 0.6604\n",
      "Epoch 9/10\n",
      "1920/1920 [==============================] - 58s 30ms/step - loss: 0.2959 - acc: 0.8812 - val_loss: 0.7721 - val_acc: 0.7271\n",
      "Epoch 10/10\n",
      "1920/1920 [==============================] - 64s 33ms/step - loss: 0.2834 - acc: 0.8870 - val_loss: 0.7603 - val_acc: 0.6979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb1e61d438>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.64      0.55      0.59       204\n",
      "       dogs       0.55      0.64      0.59       210\n",
      "      panda       0.87      0.83      0.85       186\n",
      "\n",
      "avg / total       0.68      0.67      0.67       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred.argmax(axis=1)\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "    y_test.argmax(axis=1), \n",
    "    y_pred.argmax(axis=1), \n",
    "    target_names=lb.classes_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mymodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('lb.pkl', 'wb')\n",
    "pickle.dump(lb, f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
